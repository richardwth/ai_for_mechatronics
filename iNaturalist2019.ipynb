{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version 1.13.1\nKeras version 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/richa/PycharmProjects/ai_mechatronics/')\n",
    "\n",
    "print('TensorFlow version {}'.format(tf.__version__))\n",
    "print('Keras version {}'.format(keras.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 4-th validation image locates at train_val2019/Plants/739/ffa06f951e99de9d220aee2c3309b66c.jpg; its class is 739\nThere are 265213 images in train2019.json\nThe tfrecords are saved to /media/richard/My Book/MyBackup/Data/Kaggle_iNaturalist_2019/tfrecords_299/train\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run this cell to convert the training/validation/test set to tfrecords\n",
    "\n",
    "If you want to run this code, \n",
    "1. copy this cell to a .py file and add a line to change sys.path\n",
    "2. change FLAGS.DEFAULT_DOWNLOAD to:\n",
    "/data/cephfs/punim0811/Datasets/iNaturalist/\n",
    "3. Change output_folder accordingly because I intentionally did not grant \n",
    "you writing permission to the above folder. \n",
    "\n",
    "Convertion time cost:\n",
    "    train - 7800 seconds\n",
    "    val - 100 seconds\n",
    "    test - 1100 seconds\n",
    "\"\"\"\n",
    "from GeneralTools.misc_fun import FLAGS\n",
    "FLAGS.DEFAULT_DOWNLOAD = '/media/richard/My Book/MyBackup/Data/Kaggle_iNaturalist_2019/'\n",
    "from GeneralTools.inaturalist_func import images_to_tfrecords\n",
    "import os.path\n",
    "import json\n",
    "\n",
    "key = 'train'  # choose from {'train', 'val', 'test'}\n",
    "num_images_per_tfrecord = {'train': 11531, 'val': 3030, 'test': 17675}\n",
    "target_size = 299  # change this if you want other image resolution\n",
    "num_images_per_tfrecord = num_images_per_tfrecord[key]\n",
    "\n",
    "# read json file\n",
    "annotation_file = '{}2019.json'.format(key)\n",
    "with open(os.path.join(FLAGS.DEFAULT_DOWNLOAD, annotation_file)) as data_file:\n",
    "    image_annotations = json.load(data_file)\n",
    "\n",
    "# extract image file names and classes if provided\n",
    "images = image_annotations['images']\n",
    "annotations = image_annotations['annotations'] if 'annotations' in image_annotations else None\n",
    "image_names = [image['file_name'] for image in images]\n",
    "image_class = None if annotations is None else [annotation['category_id'] for annotation in annotations]\n",
    "image_index = 4\n",
    "print('The {}-th validation image locates at {}; its class is {}'.format(\n",
    "    image_index, image_names[image_index], 'unknown' if image_class is None else image_class[image_index]))\n",
    "num_images = len(image_names)\n",
    "print('There are {} images in {}'.format(num_images, annotation_file))\n",
    "\n",
    "# configure folders to save the data\n",
    "output_folder = os.path.join(\n",
    "    FLAGS.DEFAULT_DOWNLOAD, 'tfrecords_{}/'.format(target_size))\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "output_filename = output_folder + key\n",
    "print('The tfrecords are saved to {}'.format(output_filename))\n",
    "\n",
    "# # uncomment the following lines to do the actual conversion\n",
    "# images_to_tfrecords(\n",
    "#     image_names, output_filename, num_images_per_tfrecord, \n",
    "#     image_class=image_class, target_size=299)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_091', 'train_095', 'train_039', 'train_006', 'train_021', 'train_016', 'train_003', 'train_108', 'train_071', 'train_009', 'train_031', 'train_107', 'train_093', 'train_106', 'train_020', 'train_089', 'train_034', 'train_049', 'train_017', 'train_022', 'train_102', 'train_068', 'train_057', 'train_062', 'train_112', 'train_063', 'train_096', 'train_037', 'train_036', 'train_123', 'train_004', 'train_001', 'train_101', 'train_100', 'train_104', 'train_040', 'train_000', 'train_044', 'train_013', 'train_066', 'train_073', 'train_094', 'train_023', 'train_055', 'train_072', 'train_024', 'train_069', 'train_046', 'train_120', 'train_041', 'train_014', 'train_076', 'train_121', 'train_111', 'train_092', 'train_075', 'train_090', 'train_085', 'train_025', 'train_084', 'train_015', 'train_083', 'train_019', 'train_081', 'train_010', 'train_067', 'train_124', 'train_030', 'train_079', 'train_060', 'train_058', 'train_026', 'train_042', 'train_114', 'train_086', 'train_127', 'train_122', 'train_061', 'train_082', 'train_043', 'train_109', 'train_038', 'train_011', 'train_002', 'train_007', 'train_070', 'train_045', 'train_059', 'train_027', 'train_052', 'train_078', 'train_125', 'train_105', 'train_029', 'train_064', 'train_110', 'train_056', 'train_018', 'train_098', 'train_012', 'train_065', 'train_074', 'train_005', 'train_035', 'train_117', 'train_032', 'train_050', 'train_119', 'train_053', 'train_054', 'train_087', 'train_118', 'train_115', 'train_099', 'train_028', 'train_116', 'train_033', 'train_051', 'train_113', 'train_088', 'train_080', 'train_097', 'train_047', 'train_126', 'train_103', 'train_008', 'train_077', 'train_048']\nNumber of 61 instances skipped.\nThe dataset repeats for infinite number of epochs\n",
      "(64, 1010)\nfloat32\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell reads the train/vali/test tfrecords, and visualize one sample from\n",
    "the batch.\n",
    "\n",
    "If you want to run this code, \n",
    "1. copy this cell to a .py file and add a line to change sys.path\n",
    "2. change FLAGS.DEFAULT_IN to:\n",
    "/data/cephfs/punim0811/Datasets/iNaturalist/tfrecords_299/\n",
    "or your local machine address accordingly if you decide to download \n",
    "some tfrecords file.\n",
    "3. Note that on Spartan, im.show() would not work. However, you may save the \n",
    "example you want to visualize, e.g., im.save('test_image.jpg', 'JPEG')\n",
    "\"\"\"\n",
    "from GeneralTools.misc_fun import FLAGS\n",
    "FLAGS.DEFAULT_IN = '/media/richard/ExtraStorage/Data/inaturalist_NHWC_800/'\n",
    "FLAGS.IMAGE_FORMAT = 'channels_last'\n",
    "FLAGS.IMAGE_FORMAT_ALIAS = 'NHWC'\n",
    "from GeneralTools.inaturalist_func import ReadTFRecords\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64\n",
    "target_size = 800\n",
    "key = 'train'\n",
    "data_size = {'train': 265213, 'val': 3030, 'test': 35350}\n",
    "data_label = {'train': 1, 'val': 1, 'test': 0}\n",
    "num_images = data_size[key]\n",
    "steps_per_epoch = num_images // batch_size\n",
    "skip_count = num_images % batch_size\n",
    "num_labels = data_label[key]\n",
    "num_classes = 1010\n",
    "    \n",
    "filenames = os.listdir(FLAGS.DEFAULT_IN)\n",
    "filenames = [filename.replace('.tfrecords', '') for filename in filenames if key in filename]\n",
    "print(filenames)\n",
    "\n",
    "dataset = ReadTFRecords(\n",
    "    filenames, num_labels=num_labels, batch_size=batch_size, buffer_size=500,\n",
    "    skip_count=skip_count, num_threads=8, decode_jpeg=True, \n",
    "    use_one_hot_label=True, num_classes=num_classes)\n",
    "dataset.image_preprocessor(3, target_size, target_size)\n",
    "data_batch = dataset.next_batch()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if key == 'test':\n",
    "        x = sess.run(data_batch['x'])\n",
    "    else:\n",
    "        x, y = sess.run([data_batch['x'], data_batch['y']])\n",
    "\n",
    "# visualize one sample from the batch\n",
    "x_im = x[0] * 255\n",
    "im = Image.fromarray(x_im.astype(np.uint8), 'RGB')\n",
    "im.show()\n",
    "\n",
    "if key in {'train', 'val'}:\n",
    "    print(y.shape)\n",
    "    print(y.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target_size' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a503f078d67c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     input_shape=(target_size, target_size, 3))\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;31m# Freeze some layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'target_size' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell train a pre-trained model with extra layers\n",
    "\n",
    "\"\"\"\n",
    "# keras pretrained inception v3 model\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import optimizers, applications\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
    "from tensorflow.keras import backend as K \n",
    "\n",
    "# load the model\n",
    "model = applications.InceptionV3(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(target_size, target_size, 3))\n",
    "# Freeze some layers\n",
    "for layer in model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "#Adding custom layers \n",
    "# x = model.output\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(1024, activation='relu')(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "# predictions = Dense(num_classes, activation='linear')(x)\n",
    "# mdl = Model(input = model.input, output = predictions)\n",
    "mdl = Sequential([\n",
    "    model, Flatten(), Dense(1024, activation='relu'), \n",
    "    Dense(num_classes, activation='linear')])\n",
    "\n",
    "mdl.compile(\n",
    "    tf.train.AdamOptimizer(learning_rate=0.001), \n",
    "    loss=tf.losses.softmax_cross_entropy, metrics=['accuracy'])\n",
    "history = mdl.fit(\n",
    "    dataset.dataset, epochs=1, callbacks=None, steps_per_epoch=20,\n",
    "    validation_data=None, validation_steps=200, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following tfrecords are read: ['train_006', 'train_021', 'train_016', 'train_003', 'train_009', 'train_020', 'train_017', 'train_022', 'train_004', 'train_001', 'train_000', 'train_013', 'train_014', 'train_015', 'train_019', 'train_010', 'train_011', 'train_002', 'train_007', 'train_018', 'train_012', 'train_005', 'train_008']\nNumber of 1 instances skipped.\nThe dataset repeats for infinite number of epochs\n",
      "0.900099\n"
     ]
    }
   ],
   "source": [
    "from GeneralTools.misc_fun import FLAGS\n",
    "FLAGS.DEFAULT_IN = '/media/richard/ExtraStorage/Data/inaturalist_NHWC_299/'\n",
    "FLAGS.IMAGE_FORMAT = 'channels_last'\n",
    "FLAGS.IMAGE_FORMAT_ALIAS = 'NHWC'\n",
    "import os\n",
    "if FLAGS.MIXED_PRECISION:\n",
    "    os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "from GeneralTools.inaturalist_func import read_inaturalist\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "allow_growth = False\n",
    "target_size = 299\n",
    "num_classes = 1010\n",
    "key = 'train'\n",
    "\n",
    "# read the dataset\n",
    "dataset_tr, steps_per_tr_epoch = read_inaturalist(\n",
    "    key, batch_size=2, target_size=target_size, do_augment=True)\n",
    "data_batch = dataset_tr.next_batch()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if key == 'test':\n",
    "        x = sess.run(data_batch['x'])\n",
    "        y = ['None']\n",
    "    else:\n",
    "        x, y = sess.run([data_batch['x'], data_batch['y']])\n",
    "\n",
    "# visualize one sample from the batch\n",
    "x_im = x[0] * 255\n",
    "im = Image.fromarray(x_im.astype(np.uint8), 'RGB')\n",
    "im.show()\n",
    "if key != 'test':\n",
    "    print(np.amax(y[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following tfrecords are read: ['train_000', 'train_001', 'train_002', 'train_003', 'train_004', 'train_005', 'train_006', 'train_007', 'train_008', 'train_009', 'train_010', 'train_011', 'train_012', 'train_013', 'train_014', 'train_015', 'train_016', 'train_017', 'train_018', 'train_019', 'train_020', 'train_021', 'train_022']\nThe dataset repeats for infinite number of epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 1.0)\n(-0.98921096, 0.7570392)\n"
     ]
    }
   ],
   "source": [
    "from GeneralTools.misc_fun import FLAGS\n",
    "FLAGS.DEFAULT_IN = 'C:/Users/richa/PycharmProjects/ai_mechatronics/Datasets/tfrecords_299'\n",
    "FLAGS.IMAGE_FORMAT = 'channels_last'\n",
    "FLAGS.IMAGE_FORMAT_ALIAS = 'NHWC'\n",
    "import os\n",
    "if FLAGS.MIXED_PRECISION:\n",
    "    os.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\n",
    "from GeneralTools.inaturalist_func import read_inaturalist\n",
    "from GeneralTools.inception_preprocessing import preprocess_image\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "allow_growth = False\n",
    "target_size = 299\n",
    "num_classes = 1010\n",
    "key = 'train'\n",
    "\n",
    "# read the dataset\n",
    "dataset_tr, steps_per_tr_epoch = read_inaturalist(\n",
    "    key, batch_size=1, target_size=target_size, do_augment=False)\n",
    "data_batch = dataset_tr.next_batch()\n",
    "\n",
    "image = data_batch['x'][0]\n",
    "\n",
    "image_aug = preprocess_image(\n",
    "    image, height=target_size, \n",
    "    width=target_size, is_training=True if key == 'train' else False, fast_mode=False)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    x, xa = sess.run([image, image_aug])\n",
    "\n",
    "# visualize one sample from the batch\n",
    "print((np.amin(x), np.amax(x)))\n",
    "print((np.amin(xa), np.amax(xa)))\n",
    "\n",
    "x_im = x * 255.0\n",
    "x_im2 = (xa + 1.0) * 127.5\n",
    "stack_im = np.hstack((x_im.astype(np.uint8),x_im2.astype(np.uint8)))\n",
    "Image.fromarray(stack_im).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-d24de852",
   "language": "python",
   "display_name": "PyCharm (test)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
