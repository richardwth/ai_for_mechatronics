{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GeneralTools.misc_fun import FLAGS\n",
    "\n",
    "FLAGS.TENSORFLOW_VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n(60000,)\nx_train range: 0 - 255\ny_train range: 0 - 9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# load the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print('x_train range: {} - {}'.format(np.amin(x_train), np.amax(x_train)))\n",
    "print('y_train range: {} - {}'.format(np.amin(y_train), np.amax(y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File C:/Users/richa/PycharmProjects/ai_mechatronics/Datasets/fashionmnist\\fashionmnist_train.tfrecords already exists.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os.path\n",
    "from GeneralTools.misc_fun import FLAGS\n",
    "\"\"\"\n",
    "Here we show how to save data to tfrecords\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# define macro\n",
    "# FloatList, Int64List and BytesList are three base feature types\n",
    "def _float_feature(value):\n",
    "    # Returns a float_list from a float / double.\n",
    "    return tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=[value])\n",
    "        if isinstance(value, float) else tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    # Returns an int64_list from a bool / enum / int / uint\n",
    "    # numpy int is not int!\n",
    "    return tf.train.Feature(\n",
    "        int64_list=tf.train.Int64List(value=[value])\n",
    "        if isinstance(value, int) else tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    # Returns a bytes_list from a string / byte.\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[value])\n",
    "        if isinstance(value, (str, bytes)) else tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "file_path = os.path.join(FLAGS.DEFAULT_IN, 'fashionmnist', 'fashionmnist_train.tfrecords')\n",
    "if not os.path.exists(file_path):\n",
    "    writer = tf.python_io.TFRecordWriter(file_path)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], -1))  # x_train shape [6000, 784]\n",
    "    \"\"\"\n",
    "    In case the data is too large, we need to read them one-by-one and \n",
    "    save them to multiple tfrecord files. Optimally, each tfrecord file \n",
    "    may be around 100 MB (no larger than 1 GB for faster parallel reading)\n",
    "    \"\"\"\n",
    "    for image_flat, label in zip(x_train, y_train):\n",
    "        instance = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'x': _bytes_feature(image_flat.tobytes()),\n",
    "            'y': _int64_feature(int(label))  # numpy int is not int!\n",
    "        }))\n",
    "        writer.write(instance.SerializeToString())\n",
    "    \n",
    "    writer.close()  # or put everything under: with ... as writer:\n",
    "    print('Writing to tfrecords file finished.')\n",
    "else:\n",
    "    print('File {} already exists.'.format(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext_6:0\", shape=(?, 1, 28, 28), dtype=float32)\nTensor(\"IteratorGetNext_6:1\", shape=(?, 1), dtype=int32)\nTensor(\"IteratorGetNext_6:0\", shape=(64, 1, 28, 28), dtype=float32)\nTensor(\"IteratorGetNext_6:1\", shape=(64, 1), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1, 28, 28)\n(64, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from GeneralTools.misc_fun import FLAGS\n",
    "\"\"\"\n",
    "Here we show how to read data from tfrecords\n",
    "\"\"\"\n",
    "# possible dtypes are tf.float32, tf.int64 and tf.string, \n",
    "# depending on how we save the data\n",
    "x_dtype = tf.string\n",
    "y_dtype = tf.int64\n",
    "num_samples = 60000\n",
    "num_features = 784  # 28x28\n",
    "num_labels = 1\n",
    "\n",
    "\n",
    "def my_parser(example_proto):\n",
    "    \"\"\" This function parses a single datum\n",
    "    \n",
    "    :param example_proto: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # parse a single example\n",
    "    # if tf.string, the length of features is [] (that is, 1)\n",
    "    x_config = tf.FixedLenFeature([], tf.string)\\\n",
    "        if x_dtype == tf.string else tf.FixedLenFeature([num_features], x_dtype)\n",
    "    y_config = tf.FixedLenFeature([], tf.string)\\\n",
    "        if y_dtype == tf.string else tf.FixedLenFeature([num_labels], y_dtype)\n",
    "    proto_config = {'x': x_config, 'y': y_config}\n",
    "    datum = tf.parse_single_example(example_proto, features=proto_config)\n",
    "    \n",
    "    # cast datum to data types suitable for downstream processing\n",
    "    if x_dtype == tf.string:\n",
    "        # first decode data to uint8, as data is stored in this way\n",
    "        datum['x'] = tf.decode_raw(datum['x'], tf.uint8)\n",
    "        # then cast data to tf.float32\n",
    "        datum['x'] = tf.cast(datum['x'], tf.float32)\n",
    "    if y_dtype == tf.string:\n",
    "        # avoid using string labels like 'cat', 'dog', use integers instead\n",
    "        datum['y'] = tf.decode_raw(datum['y'], tf.uint8)\n",
    "        datum['y'] = tf.cast(datum['y'], tf.int32)\n",
    "    if y_dtype == tf.int64:\n",
    "        datum['y'] = tf.cast(datum['y'], tf.int32)\n",
    "        \n",
    "    # do the following pre-processing\n",
    "    # since we know x is image, we could reshape it here\n",
    "    # otherwise, we could always add dataset.map somewhere later\n",
    "    datum['x'] = tf.divide(datum['x'], 255.0)\n",
    "    if FLAGS.IMAGE_FORMAT is 'channels_first':\n",
    "        datum['x'] = tf.reshape(datum['x'], (1, 28, 28))\n",
    "    else:\n",
    "        datum['x'] = tf.reshape(datum['x'], (28, 28, 1))\n",
    "        \n",
    "    return datum['x'], datum['y']\n",
    "    \n",
    "\n",
    "file_path = os.path.join(FLAGS.DEFAULT_IN, 'fashionmnist', 'fashionmnist_train.tfrecords')\n",
    "dataset = tf.data.TFRecordDataset(file_path)\n",
    "\"\"\"\n",
    "My laptop have 4 threads so I set num_parallel_calls to 4. \n",
    "Yours may have 8 or more, depending on the CPU.\n",
    "\"\"\"\n",
    "dataset = dataset.map(my_parser, num_parallel_calls=4)\n",
    "\n",
    "\"\"\"\n",
    "The rest is similar to the previous example of loading mnist in\n",
    "TensorFlow_basics_02_session_and_input.ipynb\n",
    "\"\"\"\n",
    "batch_size = 64\n",
    "num_epoch = None\n",
    "dataset = dataset.skip(num_samples // batch_size)\n",
    "dataset = dataset.shuffle(5000)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat(num_epoch)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "x_batch, y_batch = iterator.get_next()\n",
    "print(x_batch)\n",
    "print(y_batch)\n",
    "\n",
    "\"\"\"\n",
    "If the downstream requires the first dimension to be known,\n",
    "we can manually set a shape here. But use it carefully, as:\n",
    "1. this will not change the actual shape of x_batch, y_batch\n",
    "2. if there is inconsistency in shape during runtime, it may\n",
    "cause error. \n",
    "\"\"\"\n",
    "x_batch.set_shape((batch_size, 1, 28, 28))\n",
    "y_batch.set_shape((batch_size, 1))\n",
    "print(x_batch)\n",
    "print(y_batch)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    xv, yv = sess.run([x_batch, y_batch])\n",
    "    print(xv.shape)\n",
    "    print(yv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
