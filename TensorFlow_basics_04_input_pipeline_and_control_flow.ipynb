{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GeneralTools.misc_fun import FLAGS\n",
    "\n",
    "FLAGS.TENSORFLOW_VERSION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n(60000,)\nx_train range: 0 - 255\ny_train range: 0 - 9\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# load the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print('x_train range: {} - {}'.format(np.amin(x_train), np.amax(x_train)))\n",
    "print('y_train range: {} - {}'.format(np.amin(y_train), np.amax(y_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File C:/Users/richa/PycharmProjects/ai_mechatronics/Datasets/fashionmnist\\fashionmnist_train.tfrecords already exists.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os.path\n",
    "from GeneralTools.misc_fun import FLAGS\n",
    "\"\"\"\n",
    "Here we show how to save data to tfrecords\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# define macro\n",
    "# FloatList, Int64List and BytesList are three base feature types\n",
    "def _float_feature(value):\n",
    "    # Returns a float_list from a float / double.\n",
    "    return tf.train.Feature(\n",
    "        float_list=tf.train.FloatList(value=[value])\n",
    "        if isinstance(value, float) else tf.train.FloatList(value=value))\n",
    "\n",
    "\n",
    "def _int64_feature(value):\n",
    "    # Returns an int64_list from a bool / enum / int / uint\n",
    "    # numpy int is not int!\n",
    "    return tf.train.Feature(\n",
    "        int64_list=tf.train.Int64List(value=[value])\n",
    "        if isinstance(value, int) else tf.train.Int64List(value=value))\n",
    "\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    # Returns a bytes_list from a string / byte.\n",
    "    return tf.train.Feature(\n",
    "        bytes_list=tf.train.BytesList(value=[value])\n",
    "        if isinstance(value, (str, bytes)) else tf.train.BytesList(value=value))\n",
    "\n",
    "\n",
    "file_path = os.path.join(FLAGS.DEFAULT_IN, 'fashionmnist', 'fashionmnist_train.tfrecords')\n",
    "if not os.path.exists(file_path):\n",
    "    writer = tf.python_io.TFRecordWriter(file_path)\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], -1))  # x_train shape [6000, 784]\n",
    "    \"\"\"\n",
    "    In case the data is too large, we need to read them one-by-one and \n",
    "    save them to multiple tfrecord files. Optimally, each tfrecord file \n",
    "    may be around 100 MB (no larger than 1 GB for faster parallel reading)\n",
    "    \"\"\"\n",
    "    for image_flat, label in zip(x_train, y_train):\n",
    "        instance = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'x': _bytes_feature(image_flat.tobytes()),\n",
    "            'y': _int64_feature(int(label))  # numpy int is not int!\n",
    "        }))\n",
    "        writer.write(instance.SerializeToString())\n",
    "    \n",
    "    writer.close()  # or put everything under: with ... as writer:\n",
    "    print('Writing to tfrecords file finished.')\n",
    "else:\n",
    "    print('File {} already exists.'.format(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"IteratorGetNext_6:0\", shape=(?, 1, 28, 28), dtype=float32)\nTensor(\"IteratorGetNext_6:1\", shape=(?, 1), dtype=int32)\nTensor(\"IteratorGetNext_6:0\", shape=(64, 1, 28, 28), dtype=float32)\nTensor(\"IteratorGetNext_6:1\", shape=(64, 1), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 1, 28, 28)\n(64, 1)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from GeneralTools.misc_fun import FLAGS\n",
    "\"\"\"\n",
    "Here we show how to read data from tfrecords\n",
    "\"\"\"\n",
    "# possible dtypes are tf.float32, tf.int64 and tf.string, \n",
    "# depending on how we save the data\n",
    "x_dtype = tf.string\n",
    "y_dtype = tf.int64\n",
    "num_samples = 60000\n",
    "num_features = 784  # 28x28\n",
    "num_labels = 1\n",
    "\n",
    "\n",
    "def my_parser(example_proto):\n",
    "    \"\"\" This function parses a single datum\n",
    "    \n",
    "    :param example_proto: \n",
    "    :return: \n",
    "    \"\"\"\n",
    "    # parse a single example\n",
    "    # if tf.string, the length of features is [] (that is, 1)\n",
    "    x_config = tf.FixedLenFeature([], tf.string)\\\n",
    "        if x_dtype == tf.string else tf.FixedLenFeature([num_features], x_dtype)\n",
    "    y_config = tf.FixedLenFeature([], tf.string)\\\n",
    "        if y_dtype == tf.string else tf.FixedLenFeature([num_labels], y_dtype)\n",
    "    proto_config = {'x': x_config, 'y': y_config}\n",
    "    datum = tf.parse_single_example(example_proto, features=proto_config)\n",
    "    \n",
    "    # cast datum to data types suitable for downstream processing\n",
    "    if x_dtype == tf.string:\n",
    "        # first decode data to uint8, as data is stored in this way\n",
    "        datum['x'] = tf.decode_raw(datum['x'], tf.uint8)\n",
    "        # then cast data to tf.float32\n",
    "        datum['x'] = tf.cast(datum['x'], tf.float32)\n",
    "    if y_dtype == tf.string:\n",
    "        # avoid using string labels like 'cat', 'dog', use integers instead\n",
    "        datum['y'] = tf.decode_raw(datum['y'], tf.uint8)\n",
    "        datum['y'] = tf.cast(datum['y'], tf.int32)\n",
    "    if y_dtype == tf.int64:\n",
    "        datum['y'] = tf.cast(datum['y'], tf.int32)\n",
    "        \n",
    "    # do the following pre-processing\n",
    "    # since we know x is image, we could reshape it here\n",
    "    # otherwise, we could always add dataset.map somewhere later\n",
    "    datum['x'] = tf.divide(datum['x'], 255.0)\n",
    "    if FLAGS.IMAGE_FORMAT is 'channels_first':\n",
    "        datum['x'] = tf.reshape(datum['x'], (1, 28, 28))\n",
    "    else:\n",
    "        datum['x'] = tf.reshape(datum['x'], (28, 28, 1))\n",
    "        \n",
    "    return datum['x'], datum['y']\n",
    "    \n",
    "\n",
    "file_path = os.path.join(FLAGS.DEFAULT_IN, 'fashionmnist', 'fashionmnist_train.tfrecords')\n",
    "dataset = tf.data.TFRecordDataset(file_path)\n",
    "\"\"\"\n",
    "My laptop have 4 threads so I set num_parallel_calls to 4. \n",
    "Yours may have 8 or more, depending on the CPU.\n",
    "\"\"\"\n",
    "dataset = dataset.map(my_parser, num_parallel_calls=4)\n",
    "\n",
    "\"\"\"\n",
    "The rest is similar to the previous example of loading mnist in\n",
    "TensorFlow_basics_02_session_and_input.ipynb\n",
    "\"\"\"\n",
    "batch_size = 64\n",
    "num_epoch = None\n",
    "dataset = dataset.skip(num_samples % batch_size)\n",
    "dataset = dataset.shuffle(5000)\n",
    "dataset = dataset.batch(batch_size)\n",
    "dataset = dataset.repeat(num_epoch)\n",
    "\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "x_batch, y_batch = iterator.get_next()\n",
    "print(x_batch)\n",
    "print(y_batch)\n",
    "\n",
    "\"\"\"\n",
    "If the downstream requires the first dimension to be known,\n",
    "we can manually set a shape here. But use it carefully, as:\n",
    "1. this will not change the actual shape of x_batch, y_batch\n",
    "2. if there is inconsistency in shape during runtime, it may\n",
    "cause error. \n",
    "\"\"\"\n",
    "x_batch.set_shape((batch_size, 1, 28, 28))\n",
    "y_batch.set_shape((batch_size, 1))\n",
    "print(x_batch)\n",
    "print(y_batch)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    xv, yv = sess.run([x_batch, y_batch])\n",
    "    print(xv.shape)\n",
    "    print(yv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\richa\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n1.0 1.0\n1.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0\n2.0 1.0\n1.0 1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n1.0 1.0\n1.0 2.0\n1.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "Control flows in Python\n",
    "1. label\n",
    "2. sequence\n",
    "3. subroutine\n",
    "4. Choices\n",
    "5. loop\n",
    "6. Exceptions\n",
    "7. Generator\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "2. sequence\n",
    "Let's examine the sequential logic of TensorFlow\n",
    "\n",
    "Example obtained from:\n",
    "https://stackoverflow.com/questions/55094952/understanding-tensorflow-control-dependencies\n",
    "\"\"\"\n",
    "with tf.Graph().as_default():\n",
    "    v1 = tf.Variable(0.0, name='v1')\n",
    "    v2 = tf.Variable(0.0, name='v2')\n",
    "    upd1 = tf.assign(v1, v2 + 1.0)\n",
    "    upd2 = tf.assign(v2, v1 + 1.0)\n",
    "    \n",
    "    for i in range(10):\n",
    "        # by creating another session and run initializer,\n",
    "        # we repeatedly re-initialize v1 and v2\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run((upd1, upd2))\n",
    "            print(*sess.run([v1, v2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2.0\n1.0 2.0\n1.0 2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "2. sequence\n",
    "\n",
    "TensorFlow declarations only define dependencies; \n",
    "the order of execution is decided/optimised by TensorFlow\n",
    "\"\"\"\n",
    "\n",
    "# solution 1: be clear on the dependencies\n",
    "with tf.Graph().as_default():\n",
    "    v1 = tf.Variable(0.0, name='v1')\n",
    "    v2 = tf.Variable(0.0, name='v2')\n",
    "    upd1 = tf.assign(v1, v2 + 1.0)\n",
    "    \n",
    "    # make v2 dependent on upd1\n",
    "    upd2 = tf.assign(v2, upd1 + 1.0)\n",
    "    \n",
    "    for i in range(10):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run((upd1, upd2))\n",
    "            print(*sess.run([v1, v2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n1.0 2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 2.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "2. sequence\n",
    "\n",
    "TensorFlow declarations only define dependencies; \n",
    "the order of execution is decided/optimised by TensorFlow\n",
    "\"\"\"\n",
    "\n",
    "# solution 2: control dependencies\n",
    "with tf.Graph().as_default():\n",
    "    v1 = tf.Variable(0.0, name='v1')\n",
    "    v2 = tf.Variable(0.0, name='v2')\n",
    "    upd1 = tf.assign(v1, v2 + 1.0)\n",
    "    \n",
    "    with tf.control_dependencies([upd1]):\n",
    "        upd2 = tf.assign(v2, v1 + 1.0)\n",
    "        \n",
    "    for i in range(10):\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            sess.run((upd1, upd2))\n",
    "            print(*sess.run([v1, v2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e9fe57fb9e3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mv2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'v2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mv1\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mupd2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    651\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m     \"\"\"\n\u001b[1;32m--> 653\u001b[1;33m     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n\u001b[0m\u001b[0;32m    654\u001b[0m                     \u001b[1;34m\"Use `if t is not None:` instead of `if t:` to test if a \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    655\u001b[0m                     \u001b[1;34m\"tensor is defined, and use TensorFlow ops such as \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor."
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "4. choices\n",
    "tf.Tensor and tf.Variable cannot be used in if-else logic\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    v1 = tf.random_normal((), 0.0, 1.0)\n",
    "    v2 = tf.Variable(0.0, name='v2')\n",
    "    if v1 > 0.0:\n",
    "        upd2 = tf.assign(v2, v1 + 1.0)\n",
    "    else:\n",
    "        upd2 = tf.assign(v2, v1 - 1.0)\n",
    "        \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(upd2)\n",
    "        print(sess.run(v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.5119574\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "4. choices\n",
    "tf.Tensor and tf.Variable cannot be used in if-else logic\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution 1: tf.cond\n",
    "with tf.Graph().as_default():\n",
    "    v1 = tf.random_normal((), 0.0, 1.0)\n",
    "    v2 = tf.Variable(0.0, name='v2')\n",
    "    \"\"\"\n",
    "    It's very tricky to get tf.cond run correctly.\n",
    "    1. remember that both branches (true or false) will be executed;\n",
    "    2. both branches must return tensor of the same shape and structure\n",
    "    3. function must be passed to both branches\n",
    "    4. the condition must be a scalar\n",
    "    \"\"\"\n",
    "    upd2 = tf.cond(\n",
    "        tf.math.greater(v1, 0.0),  # condition\n",
    "        lambda: tf.assign(v2, v1 + 1.0),  # if true, return this\n",
    "        lambda: tf.assign(v2, v1 - 1.0))  # if false, return this\n",
    "    \"\"\"\n",
    "    More traditional way to define functions:\n",
    "    def fun1(): return tf.assign(v2, v1 + 1.0)\n",
    "    def fun2(): return tf.assign(v2, v1 - 1.0)\n",
    "    upd2 = tf.cond(tf.math.greater(v1, 0.0), fun1, fun2)\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(upd2)\n",
    "        print(sess.run(v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7988036   1.6768947 ]\n [ 0.41337365 -0.49068892]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "4. choices\n",
    "tf.Tensor and tf.Variable cannot be used in if-else logic\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# solution 2: tf.where\n",
    "with tf.Graph().as_default():\n",
    "    v1 = tf.random_normal((2, 2), 0.0, 1.0)\n",
    "    v2 = tf.Variable(tf.zeros((2, 2)), name='v2')\n",
    "    \"\"\"\n",
    "    Again, both branches will be executed, but tf.where\n",
    "    supports a whole tensor as conditions\n",
    "    \n",
    "    The condition shape must match the shape of returned value,\n",
    "    or the first dimension of the returned value\n",
    "    \"\"\"\n",
    "    upd2 = tf.where(\n",
    "        tf.math.greater(v1, 0.0),  # element-wise condition\n",
    "        tf.assign(v2, v1 + 1.0),  # element-wisely, if true, return this\n",
    "        tf.assign(v2, v1 - 1.0))  # element-wisely, if false, return this\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        sess.run(upd2)\n",
    "        print(sess.run(v2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\richa\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "4. loop\n",
    "\n",
    "Everything before session.run is graph declaration.\n",
    "Python for-loop add many and repetitive nodes into the graph.\n",
    "When the number of iteration is high or each iter is costly, \n",
    "Python for-loop wastes memory.\n",
    "\n",
    "tf.while_loop avoids adding repetitive nodes.\n",
    "\n",
    "tf.while_loop(\n",
    "    cond,  # when to stop while loop\n",
    "    body,  # what to calculate in each iteration\n",
    "    loop_vars,  # what variables are calculated in the loop\n",
    "    ...)\n",
    "The tricky part is that cond, body, loop_vars need to have the \n",
    "same number of inputs and loop_vars need to be list/tuple\n",
    "\n",
    "Check below for examples: \n",
    "http://mlexplore.org/2018/03/27/tensorflow-conditionals-and-while-loops/\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# a simple example\n",
    "with tf.Graph().as_default():\n",
    "    # if shape of any loop_vars would change, specify the variable shape\n",
    "    # as None in shape_invariants argument.\n",
    "    _, m_final = tf.while_loop(\n",
    "        cond=lambda i, m: i < 5, \n",
    "        body=lambda i, m: [i+1, tf.concat([m, m], axis=0)], \n",
    "        loop_vars=[tf.constant(0), tf.ones([2, 2])],\n",
    "        shape_invariants=[tf.TensorShape([]), tf.TensorShape([None, 2])],\n",
    "        name='simple_loop')\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        mv = sess.run(m_final)\n",
    "    \n",
    "    print(mv.shape)\n",
    "\n",
    "\"\"\"\n",
    "TODO:\n",
    "As a task, please try to realize the algorithm using tf.while_loop: \n",
    "    power iteration for convolution\n",
    "    Given a convolution kernel k of size (3, 3, 64, 128), with SAME pool,\n",
    "    stride 1, dilation 1, do:\n",
    "    1. initialize u as a random image\n",
    "    2. do the following loop\n",
    "        for i in range(max_iter): \n",
    "            v = conv(k ,u)\n",
    "            v = v / norm(v)\n",
    "            u = transpose-conv(k, v)\n",
    "            u = u / norm(u)\n",
    "    3. estimate the largest singular value: sigma = norm(conv(k ,u))\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\richa\\AppData\\Local\\conda\\conda\\envs\\py36\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 2)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\"\"\"\n",
    "4. loop\n",
    "\n",
    "loop are sometimes used to run similar functions, each with a \n",
    "different input. This can be done in parallel using tf.map_fun \n",
    "and tf.scan.\n",
    "\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
